{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da8eb767-1c3c-4114-99fc-1c55c9476c0a",
   "metadata": {},
   "source": [
    "# **This notebook is meant to compute the difference between the temperature mesured by the fish and the temperature from mars model**\n",
    "___\n",
    "### **Summary:**\n",
    "> **I:** Opening the data from mars model and data from fish tags.   \n",
    "> **II:** Conversion of from sigma level to depth.   \n",
    "> **III:** Resampling the tag? data to match the time of the model and the time of observation.   \n",
    "> **IV:** Definition and application of the ufunc with xr.applyufunc().  \n",
    "> **V:** Running of the computation with dask.   \n",
    "> **VI:** Saving the diff dataset to a netcdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bdf34f-b346-46eb-b9a0-da1b2e728add",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import dask\n",
    "import intake\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bc3dba34-ddb0-4c3b-a546-e6d771a45f48",
   "metadata": {
    "tags": []
   },
   "source": [
    "import holoviews as hv\n",
    "import hvplot.xarray\n",
    "\n",
    "hv.output(widget_location=\"bottom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc937595-002b-441c-9d86-671fc0820b8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "___\n",
    "## **I: Opening the data from mars model and data from fish tags.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef91d89c-f017-437e-ab23-1892393f1730",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "tag_id = os.environ.get(\"tag_id\", \"SV_A11981\")\n",
    "model = os.environ.get(\"model\", \"f1_e2500\")\n",
    "basepath = os.environ.get(\"basepath\", \"../data_local/\")\n",
    "basepath = os.environ.get(\"basepath\", \"/home/datawork-lops-iaocea/work/fish/marc/\")\n",
    "year = os.environ.get(\"year\", \"2022\")\n",
    "\n",
    "catalogue = \"https://data-taos.ifremer.fr/kerchunk/ref-marc.yaml\"\n",
    "catalogue = \"/home/datawork-taos-s/intranet/kerchunk/ref-marc.yaml\"\n",
    "\n",
    "\n",
    "outzarr = True\n",
    "if outzarr:\n",
    "    output_filename = basepath + \"diff/\" + tag_id + \"-\" + model + \".zarr\"\n",
    "else:\n",
    "    output_filename = basepath + \"diff/\" + tag_id + \"-\" + model + \".nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e16c7a-2b70-44a8-87d7-10e1afb2b1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_id, model, basepath, year, catalogue, output_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ad38ca-413e-4936-b39e-77520c5f9c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tag_url = basepath + \"tag_nc/\" + tag_id + \".nc\"\n",
    "fish = xr.open_dataset(tag_url, engine=\"h5netcdf\")\n",
    "fish  # .compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4cd7f5-f27b-430f-a2a8-75dd386c3a96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if model == \"rang0\":\n",
    "    catalogue = \"/home/datawork-lops-iaocea/catalog/intake/agrif_archive.yaml\"\n",
    "    cat = intake.open_catalog(catalogue)[\"agrif_archive\"]\n",
    "    region = \"rejeu_agrif_2016\"\n",
    "elif model == \"f1_e2500\":\n",
    "    cat = intake.open_catalog(catalogue)[\"marc\"]\n",
    "    region = model\n",
    "else:\n",
    "    cat = intake.open_catalog(catalogue)[\"marc\"]\n",
    "    region = \"f1_e2500_agrif/MARC_F1-MARS3D-\" + str.upper(model)\n",
    "ds = (cat(region=region, year=year).to_dask())[\n",
    "    [\"H0\", \"level\", \"XE\", \"theta\", \"b\", \"hc\", \"TEMP\"]\n",
    "]  # .chunk(\n",
    "# chunks={\"ni\": -1, \"nj\": -1, \"time\": 1, \"level\": -1})\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac81545-339c-4166-a14e-d34e88b4fe7c",
   "metadata": {},
   "source": [
    "## Set up dask enviroment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb17fb6-a987-4de8-ba6c-40bf58161a75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dask_hpcconfig\n",
    "\n",
    "# cluster = dask_hpcconfig.cluster(\"datarmor-local\")\n",
    "# from distributed import Client\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "\n",
    "if model == \"rang0\" or model == \"f1_e2500\":\n",
    "    overrides = {\"cluster.cores\": 7}\n",
    "    cluster = dask_hpcconfig.cluster(\"datarmor\", **overrides)\n",
    "    cluster.scale(49)\n",
    "else:\n",
    "    cluster = dask_hpcconfig.cluster(\"datarmor-local\")\n",
    "\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f5093cb-2982-4c81-9258-a37368ab9e2f",
   "metadata": {},
   "source": [
    "\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7334de91-b96c-455f-8904-5477b6f29cc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Selecting the right time span to align the datas in time.\n",
    "\n",
    "\n",
    "if \"times\" in fish.coords:\n",
    "    fish_time_span = slice(\n",
    "        fish.times.data[0], fish.times.data[1]\n",
    "    )  # Reducing the data to the right time span\n",
    "\n",
    "    fish = fish.sel(time=fish_time_span)\n",
    "    model_time_span = slice(\n",
    "        fish.times.data[0] - np.timedelta64(30, \"m\"),\n",
    "        fish.times.data[1] + np.timedelta64(30, \"m\"),\n",
    "    )\n",
    "else:\n",
    "    model_time_span = slice(\n",
    "        fish.time[0] - np.timedelta64(30, \"m\"),\n",
    "        fish.time[-1] + np.timedelta64(30, \"m\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acf2449-a8dd-47c0-af87-98d436557345",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Chunking the data\n",
    "\n",
    "ds = (\n",
    "    ds.sel(time=model_time_span)\n",
    "    .chunk(chunks={\"ni\": -1, \"nj\": -1, \"time\": 1, \"level\": -1})\n",
    "    .unify_chunks()\n",
    ")  # .persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a64b3b-6610-4208-b1b9-f271a62698f9",
   "metadata": {},
   "source": [
    "### The datas are opened but in order to make the coordinates match, we need to convert the coordinate \"level\" to depth with a particular formula."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d24ea9-4476-411c-8ba2-0ba008e25f87",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## **II: Conversion from sigma level to depth.**   \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "147b8737-de79-4a57-9566-e51068db180d",
   "metadata": {},
   "source": [
    "ds=ds.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c43a26d-3177-4900-a7c1-fd281f0306e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_depth(marc_data):\n",
    "    ####TODO: Find why the dims are not in the same order for TEMP and z-XE, find which order is the best for optimize in memory access\n",
    "    ####TODO:  transpose is slowing down the compute, verify that rechunking should be 'before' or 'after' the transpose to make the computation faster\n",
    "\n",
    "    s = marc_data.level\n",
    "    eta = marc_data.XE\n",
    "    depth = marc_data.H0\n",
    "    a = marc_data.theta\n",
    "    b = marc_data.b\n",
    "    depth_c = marc_data.hc\n",
    "\n",
    "    C = (1.0 - b) * np.sinh(a * s) / np.sinh(a) + b * (\n",
    "        np.tanh(a * (s + 0.5)) - np.tanh(0.5 * a)\n",
    "    ) / (2.0 * np.tanh(0.5 * a))\n",
    "\n",
    "    marc_data[\"C\"] = C\n",
    "\n",
    "    marc_data[\"z\"] = (eta * (1.0 + s) + depth_c * s + (depth - depth_c) * C).astype(\n",
    "        \"float32\"\n",
    "    )\n",
    "\n",
    "    marc_data[\"depth\"] = (\n",
    "        marc_data.z - marc_data.XE\n",
    "    )  # .transpose(\"time\", \"level\",\"nj\", \"ni\")\n",
    "    marc_data[\"bottom\"] = marc_data.XE + marc_data.H0\n",
    "    marc_data[\"TEMP\"] = marc_data[\"TEMP\"]  # .transpose(\"time\", \"nj\", \"ni\", \"level\")\n",
    "    return marc_data[[\"TEMP\", \"depth\", \"bottom\", \"H0\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e944d5-ce8b-4045-a0c3-2ee365dd48e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Applying the computation,\n",
    "data_model = compute_depth(ds)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0bae4fb4-6918-4f67-9145-ebf5bac3f7a7",
   "metadata": {},
   "source": [
    "data_model=data_model.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e5bdb9-c7fd-4a8e-b220-68329f5033da",
   "metadata": {},
   "source": [
    "___\n",
    "## **III: Resampling the data to match the time of the model and the time of observation.** \n",
    "\n",
    "### Now that the datas from model and fish are loaded and that the sigma level has been converted to a depth, we need to operate on fish data to sort them well and create the right dataset (temp(time,obs), depth(time,obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02314ae-af35-41d7-8a85-0d1c08ff1d4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### Saving the data from the model.\n",
    "\n",
    "model_time = data_model.time.data\n",
    "\n",
    "### creating the bins, time groups of an hour from x:30:00 to x+1:30:00\n",
    "\n",
    "time_bins = np.append(\n",
    "    model_time - np.timedelta64(30, \"m\"), model_time[-1] + np.timedelta64(30, \"m\")\n",
    ")\n",
    "######################################################################\n",
    "\n",
    "### Using of groupby_bins to get the indexes inside each time bins\n",
    "\n",
    "time_groups = list(fish.groupby_bins(group=\"time\", bins=time_bins).groups.values())\n",
    "\n",
    "######################################################################\n",
    "### Reducing fish data to water temperature and pressure\n",
    "\n",
    "fish = fish[[\"water_temperature\", \"pressure\"]]\n",
    "\n",
    "######################################################################\n",
    "### Creating arrays of values for temperature and depth per time group\n",
    "\n",
    "fish_temp = [fish.water_temperature.isel(time=t).data for t in time_groups]\n",
    "\n",
    "fish_depth = [fish.pressure.isel(time=t).data for t in time_groups]\n",
    "\n",
    "### filling the edges of depth and temp with nans\n",
    "\n",
    "if 40 - len(fish_temp[0]) != 0:\n",
    "    print(\"filling left edge with nans\")\n",
    "    nan_list1 = [np.full(shape=40 - len(fish_temp[0]), fill_value=np.nan)]\n",
    "if 40 - len(fish_temp[-1]):\n",
    "    print(\"filling right edge with nans\")\n",
    "    nan_list2 = [np.full(shape=40 - len(fish_temp[-1]), fill_value=np.nan)]\n",
    "\n",
    "fish_temp[0] = np.append(nan_list1, fish_temp[0])\n",
    "fish_depth[0] = np.append(nan_list1, fish_depth[0])\n",
    "\n",
    "fish_temp[-1] = np.append(fish_temp[-1], nan_list2)\n",
    "fish_depth[-1] = np.append(fish_depth[-1], nan_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366c7d84-f9c1-42d2-a838-3a08b462d96e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Changing the dtype to nanosecond otherwise we cant save the data\n",
    "time = model_time.astype(\"datetime64[ns]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c75dcd-5428-4578-91c4-0cf74fc6d50b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Creating the dataset of data for each time group\n",
    "\n",
    "data_fish = xr.Dataset(\n",
    "    data_vars=dict(\n",
    "        temp=([\"time\", \"obs\"], fish_temp), depth=([\"time\", \"obs\"], fish_depth)\n",
    "    ),\n",
    "    coords=dict(time=time, obs=np.arange(0, 40)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417fbb0b-8c3b-4f90-a38b-bda38de36973",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Changigng the data model values to nanoseconds too\n",
    "\n",
    "data_model = data_model.assign_coords(time=time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab60044-24f2-4515-ad2c-5f82eb691c76",
   "metadata": {},
   "source": [
    "___\n",
    "## **IV: Definition and application of the ufunc with xr.applyufunc().**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aad3672-8e3c-4428-9f3d-e6eacffa7312",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def marc_pdf_z(model_temp, model_depth, bottom, fish_temp, fish_depth):\n",
    "    diff_temp = []\n",
    "\n",
    "    if bottom - fish_depth.max() * 0.90 < 0:\n",
    "        return np.nan\n",
    "\n",
    "    for f_i, f_depth in enumerate(\n",
    "        fish_depth\n",
    "    ):  # Looping over the depth to find the datas\n",
    "        if not np.isnan(f_depth):\n",
    "            diff_depth = np.absolute(np.absolute(model_depth) - f_depth)\n",
    "\n",
    "            idx = diff_depth.argmin()\n",
    "\n",
    "            diff_temp.append(np.absolute(fish_temp[f_i] - model_temp[idx]))\n",
    "\n",
    "    return np.mean(diff_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b3746c-5c2d-4d2f-9330-fa77751bc466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_fish = data_fish.chunk(chunks={\"time\": 1}).unify_chunks().persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f145ba3-6802-48a3-8d7d-857dac3774af",
   "metadata": {
    "tags": []
   },
   "source": [
    "___\n",
    "## **V: Running of the computation with dask.**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b244da70-8bc8-4e4b-8c7d-82dca88e5a83",
   "metadata": {},
   "source": [
    "data_model=data_model.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7723c31d-7d96-44b2-a74f-d915199df1f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diff = xr.apply_ufunc(\n",
    "    marc_pdf_z,\n",
    "    data_model.TEMP,  # .chunk(dict(level=-1)),\n",
    "    data_model.depth,  # .chunk(dict(level=-1)),\n",
    "    data_model.bottom,\n",
    "    data_fish.temp,\n",
    "    data_fish.depth,\n",
    "    input_core_dims=[[\"level\"], [\"level\"], [], [\"obs\"], [\"obs\"]],\n",
    "    exclude_dims=set((\"level\", \"obs\")),\n",
    "    vectorize=True,\n",
    "    dask=\"parallelized\",\n",
    "    output_dtypes=[data_model.TEMP.dtype],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928a4a28-0bbd-433f-81cb-3c24de6440d1",
   "metadata": {},
   "source": [
    "___\n",
    "## **VI: Saving the diff dataset to a netcdf file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044ff7b0-b0b2-42eb-a561-0a4e64fdfe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "diff = (\n",
    "    diff.to_dataset(name=\"diff_\")\n",
    "    .assign_attrs({\"tag\": \"SV_A11981\"})\n",
    "    .assign({\"H0\": data_model.H0})\n",
    "    .unify_chunks()\n",
    "    .persist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff4431f-a25f-4981-87e4-aa5c81ea2e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_dataset(ds):\n",
    "    import dask\n",
    "\n",
    "    for varname, da in ds.data_vars.items():\n",
    "        # print(varname)\n",
    "        da = da.data\n",
    "        (da,) = dask.optimize(da)\n",
    "        ds[varname].data = da\n",
    "    return ds\n",
    "\n",
    "\n",
    "diff = optimize_dataset(diff)\n",
    "diff"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb9708d4-e90b-47bf-959a-70610ded89e7",
   "metadata": {},
   "source": [
    "diff=diff.persist()\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aac0179-c39d-4962-abe2-f0e041c82c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "diff.to_zarr(output_filename, mode=\"w\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ac61a82-d601-4924-bbb9-efd111669eaf",
   "metadata": {
    "tags": []
   },
   "source": [
    "%%time\n",
    "### Converting the dataaray to a dataset\n",
    "### Saving the dataset\n",
    "diff.to_dataset(name=\"diff_\").assign_attrs({\"tag\": \"SV_A11981\"}).assign(\n",
    "    {\"H0\": data_model.H0}\n",
    ").chunk(chunks={\"ni\": -1, \"nj\": -1, \"time\": 1}).unify_chunks().to_zarr(output_filename, mode=\"w\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38afa820-326f-4d86-928e-bef1b5d2cc36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
