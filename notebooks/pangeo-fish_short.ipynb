{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# **Example Usage of Pangeo-Fish Software**\n",
    "\n",
    "\n",
    "**Overview:**\n",
    "This Jupyter notebook demonstrates the usage of the Pangeo-Fish software, a tool designed for analyzing biologging data in reference to Earth Observation (EO) data. Specifically, it utilizes data employed in the study conducted by M. Gonze et al. titled \"Combining acoustic telemetry with archival tagging to investigate the spatial dynamics of the understudied pollack *Pollachius pollachius*,\" accepted for publication in the Journal of Fish Biology.\n",
    "\n",
    "We showcase the application using the biologging tag 'A19124' attached to a pollack fish, along with reference EO data from the European Union Copernicus Marine Service Information (CMEMS) product 'NORTHWESTSHELF_ANALYSIS_FORECAST_PHY_004_013'. The biologging data consist of Data Storage Tag (DST) and teledetection by acoustic signals, along with release and recapture time and location of the species in question.  Both biologging data and the reference EO data are accessible with https and the access methods are incropolated in this notebook.   \n",
    "\n",
    "\n",
    "\n",
    "**Purpose:**\n",
    "By executing this notebook, users will learn how to set up a workflow for utilizing the Pangeo-Fish software. The workflow consists of 9 steps which are described below:\n",
    "\n",
    "1. **Configure the Notebook:** Prepare the notebook environment for analysis.\n",
    "2. **Compare Reference Model with DST Information:** Analyze and compare data from the reference model with information from the biologging data of the species in question. \n",
    "3. **Regrid the Grid from Reference Model Grid to Healpix Grid:** Transform the grid from the reference model to the Healpix grid for further analysis.\n",
    "4. **Construct Emission Matrix:** Create an emission matrix based on the transformed grid.\n",
    "5. **Compute Additional Emission Probability Matrix:** Calculate an additional emission probability matrix, particularly focusing on teledetection from acoustic signals.\n",
    "6. **Combine and Normalize Emission Matrix:** Merge the emission matrix and normalize it for further processing.\n",
    "7. **Estimate Model Parameters:** Determine the parameters of the model based on the normalized emission matrix.\n",
    "8. **Compute State Probabilities and Tracks:** Calculate the probability distribution of the species in question and compute the tracks.\n",
    "9. **Visualization:** Visualize the results of the analysis for interpretation and insight.\n",
    "\n",
    "Throughout this notebook, users will gain practical experience in setting up and executing a workflow using Pangeo-Fish, enabling them to apply similar methodologies to their own biologging data analysis tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 1. **Configure the Notebook:** Prepare the notebook environment for analysis.\n",
    "\n",
    "In this step, we sets up the notebook environment for analysis. It includes installing necessary packages, importing required libraries, setting up parameters, and configuring the cluster for distributed computing. It also retrieves the tag data needed for analysis.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "editable": true,
    "raw_mimetype": "",
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install rich zstandard\n",
    "!pip install \"xarray-healpy @ git+https://github.com/iaocea/xarray-healpy.git@0ffca6058f4008f4f22f076e2d60787fcf32ac82\"\n",
    "# !pip install -e ../.\n",
    "!pip install movingpandas more_itertools\n",
    "!pip install xarray --upgrade\n",
    "!pip install xdggs healpix-convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d23ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pint_xarray import unit_registry as ureg\n",
    "import hvplot.xarray\n",
    "import xarray as xr\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import pangeo_fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Set up execution parameters for the analysis.\n",
    "#\n",
    "# Note: This cell is tagged as parameters, allowing automatic updates when configuring with papermil.\n",
    "\n",
    "# tag_name corresponds to the name of the biologging tag name (DST identification number),\n",
    "# which is also a path for storing all the information for the specific fish tagged with tag_name.\n",
    "tag_name = \"A19124\"\n",
    "\n",
    "# tag_root specifies the root URL for tag data used for this computation.\n",
    "tag_root = \"https://data-taos.ifremer.fr/data_tmp/cleaned/tag/\"\n",
    "\n",
    "\n",
    "# scratch_root specifies the root directory for storing output files.\n",
    "scratch_root = \"s3://destine-gfts-data-lake/demo\"\n",
    "\n",
    "# storage_options specifies options for the filesystem storing output files.\n",
    "storage_options = {\n",
    "    \"anon\": False,\n",
    "    \"profile\": \"gfts\",\n",
    "    \"client_kwargs\": {\n",
    "        \"endpoint_url\": \"https://s3.gra.perf.cloud.ovh.net\",\n",
    "        \"region_name\": \"gra\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# if you are using local file system, activate following two lines\n",
    "scratch_root = \".\"\n",
    "storage_options = None\n",
    "\n",
    "# Default chunk value for time dimension.  This values depends on the configuration of your dask cluster.\n",
    "chunk_time = 24\n",
    "\n",
    "# Either to use a HEALPix grid ([\"cells\"]) or a 2D grid ([\"x\", \"y\"])\n",
    "dims = [\"x\", \"y\"]\n",
    "\n",
    "#\n",
    "# Parameters for step 2. **Compare Reference Model with DST Information:**\n",
    "#\n",
    "# bbox, bounding box, defines the latitude and longitude range for the analysis area.\n",
    "bbox = {\"latitude\": [46, 51], \"longitude\": [-8, -1]}\n",
    "\n",
    "# relative_depth_threshold defines the acceptable fish depth relative to the maximum tag depth.\n",
    "# It determines whether the fish can be considered to be in a certain location based on depth.\n",
    "relative_depth_threshold = 0.8\n",
    "\n",
    "#\n",
    "# Parameters for step 3. **Regrid the Grid from Reference Model Grid to Healpix Grid:**\n",
    "#\n",
    "# optional rotation for the HEALPix grid\n",
    "rot = {\"lat\": 0, \"lon\": 0}\n",
    "# nside defines the resolution of the healpix grid used for regridding.\n",
    "nside = 4096  # *2\n",
    "\n",
    "# min_vertices sets the minimum number of vertices for a valid transcription for regridding.\n",
    "min_vertices = 1\n",
    "\n",
    "#\n",
    "# Parameters for step 4. **Construct Emission Matrix:**\n",
    "#\n",
    "# differences_std sets the standard deviation for scipy.stats.norm.pdf.\n",
    "# It expresses the estimated certainty of the field of difference.\n",
    "differences_std = 0.75\n",
    "\n",
    "# recapture_std sets the covariance for recapture event.\n",
    "# It shows the certainty of the final recapture area if it is known.\n",
    "recapture_std = 1e-2\n",
    "\n",
    "# earth_radius defines the radius of the Earth used for distance calculations.\n",
    "earth_radius = ureg.Quantity(6371, \"km\")\n",
    "\n",
    "# maximum_speed sets the maximum allowable speed for the tagged fish.\n",
    "maximum_speed = ureg.Quantity(60, \"km / day\")\n",
    "\n",
    "# adjustment_factor adjusts parameters for a more fuzzy search.\n",
    "# It will factor the allowed maximum displacement of the fish.\n",
    "adjustment_factor = 5\n",
    "\n",
    "# truncate sets the truncating factor for computed maximum allowed sigma for convolution process.\n",
    "truncate = 4\n",
    "\n",
    "#\n",
    "# Parameters for step 5. **Compute Additional Emission Probability Matrix:**\n",
    "#\n",
    "# receiver_buffer sets the maximum allowed detection distance for acoustic receivers.\n",
    "receiver_buffer = ureg.Quantity(1000, \"m\")\n",
    "\n",
    "#\n",
    "# Parameters for step 7. **Estimate Model Parameters:**\n",
    "#\n",
    "# tolerance sets the tolerance level for optimised parameter search computation.\n",
    "# Smaller values will make the optimization iterate more\n",
    "# In this tutorial, if 1D index (HEALPix grid) is used, we suggesting the value to 1e-6\n",
    "tolerance = 1e-3 if dims == [\"x\", \"y\"] else 1e-6\n",
    "\n",
    "#\n",
    "# Parameters for step 8. **Compute State Probabilities and Tracks:**\n",
    "#\n",
    "# track_modes defines the modes for track calculation.\n",
    "track_modes = [\"mean\", \"mode\"]\n",
    "\n",
    "# additional_track_quantities sets quantities to compute for tracks using moving pandas.\n",
    "additional_track_quantities = [\"speed\", \"distance\"]\n",
    "\n",
    "\n",
    "#\n",
    "# Parameters for step 9. **Visualization:**\n",
    "#\n",
    "# time_step defines for each time_step value we make movie of state and emission distributions\n",
    "time_step = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define target root directories for storing analysis results.\n",
    "target_root = f\"{scratch_root}/{tag_name}\"\n",
    "\n",
    "# Defines default chunk size for optimisation.\n",
    "default_chunk = {\"time\": chunk_time, \"lat\": -1, \"lon\": -1}\n",
    "default_chunk_dims = {\"time\": chunk_time}\n",
    "default_chunk_dims.update({d: -1 for d in dims})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up a local cluster for distributed computing.\n",
    "from distributed import LocalCluster\n",
    "\n",
    "cluster = LocalCluster()\n",
    "client = cluster.get_client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pangeo_fish.helpers import load_tag\n",
    "tag, tag_log, time_slice = load_tag(tag_root, tag_name)\n",
    "tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72599cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pangeo_fish.helpers import plot_tag\n",
    "\n",
    "plot = plot_tag(tag, tag_log, save_html=True, storage_options=storage_options, target_root=target_root)\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 2. **Compare Reference Model with DST Tag Information:** Analyze and compare data from the reference model with information from the biologging data of the species in question. \n",
    "\n",
    "In this step, we compare the reference model data with Data Storage Tag information.\n",
    "The process involves reading and cleaning the reference model, aligning time, converting depth units, subtracting tag data from the model, and saving the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "collapsed": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pangeo_fish.helpers import load_model, compute_diff\n",
    "\n",
    "reference_model = load_model(tag_log, time_slice, bbox=bbox, chunk_time=chunk_time)\n",
    "diff = compute_diff(reference_model, tag_log, relative_depth_threshold, chunk_time=chunk_time)\n",
    "diff = diff.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45be3322",
   "metadata": {},
   "source": [
    "_We can detect abnormal data by looking at the number of non null values for each timestep_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49522f93",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "diff[\"diff\"].count([\"lat\", \"lon\"]).plot()\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "diff.to_zarr(f\"{target_root}/diff.zarr\", mode=\"w\", storage_options=storage_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 3. **Regrid the Grid from Reference Model Grid to Healpix Grid:** Transform the grid from the reference model to the Healpix grid for further analysis.\n",
    "\n",
    "In this step, we regrid the data from the reference model grid to a Healpix grid. This process involves defining the Healpix grid, creating the target grid, computing interpolation weights, performing the regridding, and saving the regridded data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bcd2308-1b67-4964-bce8-d4c47afd7a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pangeo_fish.helpers import open_diff_dataset, regrid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ea952b9-4a9d-4686-b95c-19eb5239dec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the previous dataset (in case we resume the notebook)\n",
    "diff = open_diff_dataset(target_root, storage_options)\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "reshaped = regrid_dataset(\n",
    "    diff,\n",
    "    nside,\n",
    "    min_vertices=min_vertices,\n",
    "    rot=rot,\n",
    "    dims=dims\n",
    ")\n",
    "reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d4e684",
   "metadata": {},
   "source": [
    "Let's plot the same chart as before to check that the HEALPix regridding hasn't changed the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "reshaped[\"diff\"].count(dims).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "reshaped.chunk(default_chunk_dims).to_zarr(\n",
    "    f\"{target_root}/diff-regridded.zarr\",\n",
    "    mode=\"w\",\n",
    "    consolidated=True,\n",
    "    compute=True,\n",
    "    storage_options=storage_options,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 4. **Construct Emission Matrix:** Create an emission matrix based on the transformed grid.\n",
    "\n",
    "In this step, we construct the emission probability matrix based on the differences between the observed tag temperature and the reference sea temperature computed in Workflow 2 and regridded in Workflow 3. The emission probability matrix represents the likelihood of observing a specific temperature difference given the model parameters and configurations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pangeo_fish.helpers import compute_emission_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open the previous dataset (in case we resume the notebook)\n",
    "differences = xr.open_dataset(\n",
    "    f\"{target_root}/diff-regridded.zarr\",\n",
    "    engine=\"zarr\",\n",
    "    chunks={},\n",
    "    storage_options=storage_options,\n",
    ").pipe(lambda ds: ds.merge(ds[[\"latitude\", \"longitude\"]].compute()))\n",
    "# ... and compute the emission matrices\n",
    "emission_pdf = compute_emission_pdf(\n",
    "    differences,\n",
    "    tag[\"tagging_events\"].ds,\n",
    "    differences_std,\n",
    "    recapture_std,\n",
    "    dims=dims,\n",
    "    chunk_time=chunk_time\n",
    ")\n",
    "emission_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfa7a6a",
   "metadata": {},
   "source": [
    "Whatever you data, it's important to **never have** only null values at any timestep.\n",
    "\n",
    "How could we check that visually? You guess it, by using a similar plot as before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "emission_pdf = emission_pdf.chunk(default_chunk_dims).persist()\n",
    "emission_pdf[\"pdf\"].count(dims).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the dataset\n",
    "emission_pdf.to_zarr(\n",
    "    f\"{target_root}/emission.zarr\",\n",
    "    mode=\"w\",\n",
    "    consolidated=True,\n",
    "    storage_options=storage_options,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 5. **Compute Additional Emission Probability Matrix**\n",
    "Calculate an additional emission probability matrix, particularly focusing on teledetection from acoustic signals.\n",
    "\n",
    "In this step, we compute additional emission probabilities based on acoustic detections for the selected tag. \n",
    "\n",
    "These additional probabilities enhance the emission probability matrix constructed in **step 4** by incorporating information from acoustic telemetry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4f98c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pangeo_fish.helpers import compute_acoustic_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the previous emission pdf and compute the emission probabilities based on acoustic detections\n",
    "emission_pdf = xr.open_dataset(\n",
    "    f\"{target_root}/emission.zarr\",\n",
    "    engine=\"zarr\",\n",
    "    chunks={},\n",
    "    storage_options=storage_options,\n",
    ") # chunk?\n",
    "acoustic_pdf = compute_acoustic_pdf(\n",
    "    emission_pdf,\n",
    "    tag,\n",
    "    receiver_buffer,\n",
    "    chunk_time=chunk_time,\n",
    "    dims=dims\n",
    ").persist()\n",
    "acoustic_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245948a0",
   "metadata": {},
   "source": [
    "This time, we check the data as before while pinpointing when detections occur!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tag[\"acoustic\"][\"deployment_id\"].hvplot.scatter(c=\"red\", marker=\"x\") * (\n",
    "    acoustic_pdf[\"acoustic\"] != 0\n",
    ").sum(dim=dims).hvplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309cf89b",
   "metadata": {},
   "source": [
    "### Explanations\n",
    "On the plot above, at detection times the number of counted values drop to a few value (`5` in this example).\n",
    "\n",
    "These numbers correspond to the number of pixels that covers the detection area.\n",
    "\n",
    "Therefore, such drop is expected, since at those times we know that the fish was detected there, and so it can't be elsewhere.\n",
    "\n",
    "These sporadic detections will constraint a lot the geolocation model upon optimizing!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a5a193",
   "metadata": {},
   "source": [
    "**The next cell is optional. It will save the acoustic probabilities. It is not necessary (see the next step).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a80486",
   "metadata": {},
   "outputs": [],
   "source": [
    "acoustic_pdf.to_zarr(\n",
    "    f\"{target_root}/acoustic.zarr\",\n",
    "    mode=\"w\",\n",
    "    consolidated=True,\n",
    "    storage_options=storage_options,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 6. **Combine and Normalize the 2 distributions** \n",
    "Merge the `emission` distribution with the `acoustic` one and normalize it for further processing.\n",
    "\n",
    "In this step, we combine the emission probability matrix constructed in **Workflow 4** and **5** then normalize it to ensure that the probabilities sum up to one. This step prepares the combined emission matrix for further analysis and interpretation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pangeo_fish.helpers import combine_pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined = combine_pdfs(emission_pdf, acoustic_pdf, default_chunk_dims, dims=dims)\n",
    "combined.to_zarr(\n",
    "    f\"{target_root}/combined.zarr\",\n",
    "    mode=\"w\",\n",
    "    consolidated=True,\n",
    "    storage_options=storage_options,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1213a21",
   "metadata": {},
   "source": [
    "### In addition, we can check that our final temporal _pdf_ is valid, `i.e.`, it sums to `1` for all timesteps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8e8310",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined[\"pdf\"].sum(dims).plot(ylim=(0, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 7. **Estimate Model's Parameters**\n",
    "Determine the parameters of the model based on the normalized emission matrix:\n",
    "\n",
    "1. We estimate maximum allowed value of parameter we aim to optimize, namely `sigma`.  \n",
    "2. We then create an optimizer with an expected parameter range and fit the model to the normalized emission matrix.  \n",
    "3. Finally, the resulting `sigma` along with any additional parameters used during optimization is saved to a `.json` file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pangeo_fish.helpers import optimize_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d002a8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the distributions\n",
    "emission = xr.open_dataset(\n",
    "    f\"{target_root}/combined.zarr\",\n",
    "    engine=\"zarr\",\n",
    "    chunks=default_chunk_dims,\n",
    "    inline_array=True,\n",
    "    storage_options=storage_options,\n",
    ")\n",
    "# Call the optimization process\n",
    "params = optimize_pdf(\n",
    "    emission,\n",
    "    earth_radius,\n",
    "    adjustment_factor,\n",
    "    truncate,\n",
    "    maximum_speed,\n",
    "    tolerance,\n",
    "    dims=dims\n",
    ")\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results, mainly `sigma`\n",
    "import pandas as pd\n",
    "pd.DataFrame.from_dict(params, orient=\"index\").to_json(\n",
    "    f\"{target_root}/parameters.json\", storage_options=storage_options\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "## 8. **Compute State Probabilities and Trajectories**\n",
    "Calculate the probability distribution of the species in question and compute the tracks (or trajectories).\n",
    "\n",
    "This step involves predicting state probabilities using the optimised parameter sigma computed in the last step together with normalized emission matrix.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee95858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pangeo_fish.helpers import predict_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "states, trajectories = predict_positions(target_root,\n",
    "    storage_options,\n",
    "    chunks=default_chunk_dims,\n",
    "    track_modes=track_modes,\n",
    "    additional_track_quantities=additional_track_quantities,\n",
    "    dims=dims\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ddb6e1",
   "metadata": {},
   "source": [
    "Let's quickly check that the positional probability distribution `states` never sums to 0 for all timesteps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    states.sum(dims).hvplot(width=500, ylim=(0, 2), title=\"Sum of the probabilities\") +\n",
    "    states.count(dims).hvplot(width=500, title=\"Number of none-zero probabilities\")\n",
    ").opts(shared_axes=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "## 9. **Visualization** \n",
    "Visualize the results of the analysis for interpretation and insight.\n",
    "\n",
    "\n",
    "In this step, we visualize various aspects of the analysis results to gain insights and interpret the model outcomes. \n",
    "\n",
    "We plot the emission matrix, which represents the likelihood of observing a specific temperature difference given the model parameters and configurations. \n",
    "\n",
    "Additionally, we visualize the state probabilities, showing the likelihood of the system being in different states at each time step. \n",
    "\n",
    "We also plot each of the tracks of the tagged fish, displaying their movement patterns over time. \n",
    "\n",
    "Finally, we create a movie that combines the emission matrix and state probabilities to provide a comprehensive visualization of the analysis results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39da3570",
   "metadata": {},
   "source": [
    "### 9.1 Plotting the trajectories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pangeo_fish.helpers import plot_trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_trajectories(\n",
    "    target_root,\n",
    "    track_modes,\n",
    "    storage_options,\n",
    "    save_html=True\n",
    ")\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af2166a",
   "metadata": {},
   "source": [
    "### 9.2 Plotting the `states` and `emission` distributions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "113f81b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pangeo_fish.helpers import open_distributions, render_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1cedba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open_distributions(target_root, storage_options, default_chunk_dims, chunk_time=chunk_time)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f9350c",
   "metadata": {},
   "source": [
    "The interactive plot above is too large to be stored as a `HMTL` file (as done earlier with the trajectories).\n",
    "\n",
    "Fortunately, `pangeo-fish` can efficiently render images of `data` and build a video from them! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_filename = render_distributions(\n",
    "    data,\n",
    "    xlim=bbox[\"longitude\"],\n",
    "    ylim=bbox[\"latitude\"],\n",
    "    time_step=3,\n",
    "    extension=\"mp4\",\n",
    "    frames_dir=\"images\",\n",
    "    remove_frames=True\n",
    ")\n",
    "\n",
    "if target_root.startswith(\"s3://\"):\n",
    "    import s3fs\n",
    "\n",
    "    s3 = s3fs.S3FileSystem(**storage_options)\n",
    "    s3.put_file(video_filename, f\"{target_root}/{video_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff072c75-5c04-4f1f-9e02-88f4411566b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
